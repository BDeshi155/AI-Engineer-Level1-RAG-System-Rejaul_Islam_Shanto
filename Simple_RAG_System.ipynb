{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOaZbs-oVrIe",
        "outputId": "cc9270b3-3a70-4b82-93b9-e30f4b668341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDtsAxbEVmG6",
        "outputId": "c050cfe8-25e5-4da0-90dd-3f7bee91e135"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.7.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/dataset/HSC26 Bangla 1st paper.md'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\n",
        "    full_text = f.read()\n"
      ],
      "metadata": {
        "id": "l0jLIACRmk3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "# Here we use GPT-3.5/4 tokenizer\n",
        "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "def tokenize(text):\n",
        "    return tokenizer.encode(text)\n",
        "\n",
        "def detokenize(tokens):\n",
        "    return tokenizer.decode(tokens)\n",
        "\n",
        "# Hybrid Chunker with paragraph and punctuation boundaries\n",
        "def chunk_text(text, chunk_size=500, chunk_overlap=50):\n",
        "    import re\n",
        "\n",
        "    raw_splits = re.split(r'(?<=[à¥¤!?])\\s+|\\n{2,}', text)\n",
        "\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_tokens = 0\n",
        "\n",
        "    for segment in raw_splits:\n",
        "        segment = segment.strip()\n",
        "        if not segment:\n",
        "            continue\n",
        "        segment_tokens = tokenize(segment)\n",
        "        if current_tokens + len(segment_tokens) > chunk_size:\n",
        "            if current_chunk:\n",
        "                chunk = ' '.join(current_chunk)\n",
        "                chunks.append(chunk)\n",
        "                overlap_tokens = tokenize(' '.join(current_chunk))[-chunk_overlap:]\n",
        "                current_chunk = [detokenize(overlap_tokens), segment]\n",
        "                current_tokens = len(tokenize(current_chunk[0])) + len(segment_tokens)\n",
        "            else:\n",
        "                chunks.append(segment)\n",
        "                current_chunk = []\n",
        "                current_tokens = 0\n",
        "        else:\n",
        "            current_chunk.append(segment)\n",
        "            current_tokens += len(segment_tokens)\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(' '.join(current_chunk))\n",
        "\n",
        "    return chunks\n"
      ],
      "metadata": {
        "id": "L-0-3vfKnyss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = chunk_text(full_text, chunk_size=500, chunk_overlap=50)\n",
        "print(f\"âœ… Total Chunks Created: {len(chunks)}\")\n",
        "\n",
        "# Previewing some chunks\n",
        "for i, chunk in enumerate(chunks[:3]):\n",
        "    print(f\"\\n--- Chunk {i+1} ---\\n{chunk[:500]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3dyyI9Sn3I7",
        "outputId": "4edc124e-87dd-4714-e285-b02911f43c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Total Chunks Created: 133\n",
            "\n",
            "--- Chunk 1 ---\n",
            "ğŸ¯ à¦¶à¦¿à¦•à§à¦·à¦¾à¦«à¦² âœ” à¦¨à¦¿à¦°à§à¦¯à¦¾à¦¤à¦¿à¦¤ à¦¬à§à¦¯à¦•à§à¦¤à¦¿à¦° à¦¬à¦¾à¦‡à¦°à§‡ à¦¬à¦¿à¦¤à§à¦¤à¦¶à¦¾à¦²à§€ à¦¹à¦¯à¦¼à§‡ à¦“à¦ à¦¾à¦° à¦«à¦²à§‡ à¦¸à¦®à¦¾à¦œà§‡ à¦ªà¦°à¦¿à¦šà¦¯à¦¼ à¦¸à¦‚à¦•à¦Ÿ à¦¸à¦®à§à¦ªà¦°à§à¦•à§‡ à¦§à¦¾à¦°à¦£à¦¾ à¦²à¦¾à¦­ à¦•à¦°à¦¬à§‡à¥¤ âœ” à¦¤à§à¦•à¦¾à¦²à§€à¦¨ à¦¸à¦®à¦¾à¦œ-à¦¸à¦­à§à¦¯à¦¤à¦¾ à¦“ à¦®à¦¾à¦¨à¦¬à¦¤à¦¾à¦° à¦…à¦¬à¦®à¦¾à¦¨à¦¨à¦¾ à¦¸à¦®à§à¦ªà¦°à§à¦•à§‡ à¦œà¦¾à¦¨à¦¤à§‡ à¦ªà¦¾à¦°à¦¬à§‡à¥¤ âœ” à¦¤à§à¦•à¦¾à¦²à§€à¦¨ à¦¸à¦®à¦¾à¦œà§‡à¦° à¦ªà§à¦°à¦§à¦¾à¦¨à¦¤ à¦•à§à¦¸à¦‚à¦¸à§à¦•à¦¾à¦° à¦¸à¦®à§à¦ªà¦°à§à¦•à§‡ à¦œà¦¾à¦¨à¦¤à§‡ à¦ªà¦¾à¦°à¦¬à§‡à¥¤ âœ” à¦¤à§à¦•à¦¾à¦²à§€à¦¨ à¦¸à¦®à¦¾à¦œà§‡ à¦­à¦¦à§à¦°à¦²à§‹à¦•à§‡à¦° à¦¸à§à¦¬à¦­à¦¾à¦¬à¦¬à§ˆà¦¶à¦¿à¦·à§à¦Ÿà§à¦¯ à¦¸à¦®à§à¦ªà¦°à§à¦•à§‡ à¦œà§à¦à¦¾à¦¨à¦²à¦¾à¦­ à¦•à¦°à¦¬à§‡à¥¤ âœ” à¦¨à¦¾à¦°à§€ à¦•à§‹à¦®à¦² à¦ à¦¿à¦•, à¦•à¦¿à¦¨à§à¦¤à§ à¦¦à§à¦°à§à¦¬à¦² à¦¨à¦¯à¦¼ \\- à¦•à¦²à§à¦¯à¦¾à¦£à§€ à¦œà§€à¦¬à¦¨à¦šà¦°à¦¿à¦¤à§‡ à¦¦à§à¦¬à¦¾à¦°à¦¾ à¦ªà§à¦°à¦¤à¦¿à¦¸à§à¦¥à¦¾à¦ªà¦¿à¦¤ à¦à¦‡ à¦¸à¦¤à§à¦¯ à¦…à¦¨à§à¦§à¦¾à¦¬à¦¨ à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à¦¬à§‡à¥¤\n",
            "\n",
            "--- Chunk 2 ---\n",
            "à¦¾ à¦ªà§à¦°à¦¤à¦¿à¦¸à§à¦¥à¦¾à¦ªà¦¿à¦¤ à¦à¦‡ à¦¸à¦¤à§à¦¯ à¦…à¦¨à§à¦§à¦¾à¦¬à¦¨ à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à¦¬à§‡à¥¤ âœ” à¦®à¦¾à¦¨à§à¦· à¦†à¦¶à¦¾ à¦¨à¦¿à¦¯à¦¼à§‡ à¦¬à§‡à¦à¦šà§‡ à¦¥à¦¾à¦•à§‡ \\- à¦…à¦¨à§à¦ªà§à¦°à§‡à¦°à¦£à¦¾à¦° à¦¦à§ƒà¦·à§à¦Ÿà¦¿à¦¤à§‡ à¦®à¦¾à¦¨à¦¬à¦œà§€à¦¬à¦¨à§‡à¦° à¦à¦‡ à¦šà¦¿à¦¤à§à¦°à§‡à¦° à¦¸à¦¤à§à¦¯à¦¦à¦°à§à¦¶à¦¨ à¦¸à¦®à§à¦ªà¦°à§à¦•à§‡ à¦œà§à¦à¦¾à¦¨à¦²à¦¾à¦­ à¦•à¦°à¦¬à§‡à¥¤ ğŸ“˜ à¦ªà§à¦°à¦¾à¦•à§â€Œ-à¦®à§‚à¦²à§à¦¯à¦¾à¦¯à¦¼à¦¨ à§§à¥¤ à¦…à¦¨à§à¦ªà¦®à§‡à¦° à¦¬à¦¾à¦¬à¦¾ à¦•à§€ à¦•à¦°à§‡ à¦œà§€à¦¬à¦¿à¦•à¦¾ à¦¨à¦¿à¦°à§à¦¬à¦¾à¦¹ à¦•à¦°à¦¤à§‡à¦¨? à¦–) à¦“à¦•à¦¾à¦²à¦¤à¦¿ à§¨à¥¤ à¦®à¦¾à¦¯à¦¼à§‡à¦° à¦­à¦¾à¦·à¦¾ à¦¦à§‡à¦¬à¦¤à¦¾à¦° à¦ªà§à¦°à¦¾à¦§à¦¾à¦¨à§à¦¯ à¦à¦¡à¦­à¦¾à¦°à§à¦Ÿ à¦¬à¦²à¦¾à¦° à¦•à¦¾à¦°à¦£, à¦¤à¦¾à¦°- à¦—) à¦¬à¦¿à¦šà¦•à§à¦·à¦£à¦¤à¦¾ à¦¨à¦¿à¦šà§‡à¦° à¦…à¦¨à§à¦šà§à¦›à§‡à¦¦à¦Ÿà¦¿ à¦ªà¦¡à¦¼à§‡ à§© à¦“ à§ª à¦¨à¦®à§à¦¬à¦° à¦ªà§à¦°à¦¶à§à¦¨à§‡à¦° à¦‰à¦¤à§à¦¤à¦° à¦¦à¦¾à¦“à¥¤ à¦ªà¦¿à¦à¦ªà¦¡à¦¼à¦¿à¦° à¦¦à§€à¦ªà§ à¦šà¦¾à¦šà¦¾ à¦›à¦¿à¦²à§‡à¦¨ à¦ªà¦¬à¦¿à¦°à§‡à¦° à¦•à¦°à§à¦¤à§à¦¤à¦¾à¥¤\n",
            "\n",
            "--- Chunk 3 ---\n",
            "ï¿½ à¦ªà¦¿à¦à¦ªà¦¡à¦¼à¦¿à¦° à¦¦à§€à¦ªà§ à¦šà¦¾à¦šà¦¾ à¦›à¦¿à¦²à§‡à¦¨ à¦ªà¦¬à¦¿à¦°à§‡à¦° à¦•à¦°à§à¦¤à§à¦¤à¦¾à¥¤ à¦¦à§€à¦ªà§ à¦¶à¦¿à¦•à§à¦·à¦¿à¦¤ à¦¹à¦²à§‡à¦“ à¦¤à¦¾à¦° à¦¸à¦¿à¦¦à§à¦§à¦¾à¦¨à§à¦¤ à¦¨à§‡à¦“à¦¯à¦¼à¦¾à¦° à¦•à§à¦·à¦®à¦¤à¦¾ à¦›à¦¿à¦² à¦¨à¦¾à¥¤ à¦šà¦¾à¦šà¦¾ à¦¤à¦¾à¦° à¦¬à¦¿à¦¯à¦¼à§‡à¦° à¦‰à¦¦à§à¦¯à§‹à¦— à¦¨à¦¿à¦²à§‡ à¦¯à§Œà¦¤à§à¦• à¦¨à¦¿à¦¯à¦¼à§‡ à¦¬à¦¾à¦¡à¦¼à¦¾à¦¬à¦¾à¦¡à¦¼à¦¿à¦° à¦•à¦¾à¦°à¦£à§‡ à¦•à¦²à§à¦¯à¦¾à¦£à§€ à¦ªà¦¿à¦¤à¦¾ à¦…à¦ªà¦®à¦¾à¦¨à¦¿à¦¤ à¦¬à§‹à¦§ à¦•à¦°à§‡ à¦¬à¦¿à¦¯à¦¼à§‡à¦° à¦†à¦²à§‹à¦šà¦¨à¦¾à¦¤à§‡ à¦¢à§à¦•à§‡ à¦¦à§‡à¦¨à¥¤ à¦¦à§€à¦ªà§ à¦®à§‡à¦¯à¦¼à§‡à¦Ÿà¦¿à¦° à¦›à¦¬à¦¿ à¦¦à§‡à¦–à§‡ à¦®à§à¦—à§à¦§ à¦¹à¦²à§‡ à¦¤à¦¾à¦° à¦šà¦¾à¦šà¦¾à¦•à§‡ à¦•à¦¿à¦›à§à¦‡ à¦¬à¦²à¦¤à§‡ à¦ªà¦¾à¦°à§‡à¦¨à¦¨à¦¿à¥¤ à§©à¥¤ à¦¦à§€à¦ªà§à¦° à¦šà¦¾à¦šà¦¾à¦° à¦¸à¦™à§à¦—à§‡ â€˜à¦…à¦ªà§à¦°à¦¤à¦¿à¦·à§à¦ à¦¤à¦¾â€™ à¦—à¦²à§à¦ªà§‡à¦° à¦•à§‹à¦¨ à¦šà¦°à¦¿à¦¤à§à¦°à§‡à¦° à¦®à¦¿à¦² à¦†à¦›à§‡? à¦–) à¦®à¦¾à¦®à¦¾à¦° à§ªà¥¤ à¦‰à¦•à§à¦¤ à¦šà¦°à¦¿à¦¤à§à¦°à§‡ à¦ªà§à¦°à¦¾à¦§à¦¾à¦¨à§à¦¯ à¦ªà§‡à¦¯à¦¼à§‡à¦›à§‡- i) à¦¦à§Œà¦°à¦¾à¦¶ ii) à¦‡à¦šà§à¦›à§‡à¦®à§ƒà¦¤à§à¦¯à§\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = '/content/drive/MyDrive/dataset/HSC26_chunks.txt'\n",
        "with open(output_path, 'w', encoding='utf-8') as f:\n",
        "    for chunk in chunks:\n",
        "        f.write(chunk.strip() + '\\n---\\n')\n",
        "print(\"Chunks saved to:\", output_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYppGQgPn6ND",
        "outputId": "6a4b5a4f-c0ca-417e-a432-3c7c205e69c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunks saved to: /content/drive/MyDrive/dataset/HSC26_chunks.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community langchain-chroma sentence-transformers chromadb transformers torch accelerate langchain-huggingface requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import requests\n",
        "import time\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain.schema import Document\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms.base import LLM\n",
        "from typing import List, Optional, Any\n",
        "import os\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vslskXRTUr_6",
        "outputId": "056e7c2f-4939-4b58-80c2-e4192096d13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-chroma\n",
            "  Downloading langchain_chroma-0.2.5-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-0.3.1-py3-none-any.whl.metadata (996 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.70)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.16.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.1)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.2)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.73.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.11.0)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.7.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.7.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.26.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.35.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.35.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.35.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.56b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_chroma-0.2.5-py3-none-any.whl (12 kB)\n",
            "Downloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_huggingface-0.3.1-py3-none-any.whl (27 kB)\n",
            "Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.35.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.35.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.35.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.2/71.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=f7c77bcde3616d5c7c04330e0d6c93a59def825bf3936bac533a6abf386d64df\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, python-dotenv, pybase64, overrides, opentelemetry-proto, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, mmh3, marshmallow, humanfriendly, httpx-sse, httptools, bcrypt, backoff, watchfiles, typing-inspect, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, pydantic-settings, opentelemetry-semantic-conventions, onnxruntime, nvidia-cusolver-cu12, kubernetes, dataclasses-json, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, langchain-huggingface, chromadb, langchain-community, langchain-chroma\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.15 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.10 httptools-0.6.4 httpx-sse-0.4.1 humanfriendly-10.0 kubernetes-33.1.0 langchain-chroma-0.2.5 langchain-community-0.3.27 langchain-huggingface-0.3.1 marshmallow-3.26.1 mmh3-5.1.0 mypy-extensions-1.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnxruntime-1.22.1 opentelemetry-api-1.35.0 opentelemetry-exporter-otlp-proto-common-1.35.0 opentelemetry-exporter-otlp-proto-grpc-1.35.0 opentelemetry-proto-1.35.0 opentelemetry-sdk-1.35.0 opentelemetry-semantic-conventions-0.56b0 overrides-7.7.0 posthog-5.4.0 pybase64-1.4.1 pydantic-settings-2.10.1 pypika-0.48.9 python-dotenv-1.1.1 typing-inspect-0.9.0 uvloop-0.21.0 watchfiles-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HuggingFaceLLM(LLM):\n",
        "    \"\"\"\n",
        "    Custom LLM wrapper for Hugging Face Inference API (free tier)\n",
        "    \"\"\"\n",
        "    model_name: str = \"microsoft/DialoGPT-medium\"\n",
        "    api_url: str = \"\"\n",
        "\n",
        "    def __init__(self, model_name: str = \"microsoft/DialoGPT-medium\"):\n",
        "        super().__init__()\n",
        "        self.model_name = model_name\n",
        "        self.api_url = f\"https://api-inference.huggingface.co/models/{model_name}\"\n",
        "\n",
        "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
        "        \"\"\"\n",
        "        Make API call to Hugging Face\n",
        "        \"\"\"\n",
        "        api_url = \"https://api-inference.huggingface.co/models/google/flan-t5-large\"\n",
        "\n",
        "        headers = {\"Content-Type\": \"application/json\"}\n",
        "        payload = {\n",
        "            \"inputs\": prompt,\n",
        "            \"parameters\": {\n",
        "                \"max_new_tokens\": 150,\n",
        "                \"temperature\": 0.1,\n",
        "                \"return_full_text\": False\n",
        "            }\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.post(api_url, headers=headers, json=payload)\n",
        "            if response.status_code == 200:\n",
        "                result = response.json()\n",
        "                if isinstance(result, list) and len(result) > 0:\n",
        "                    return result[0].get('generated_text', '').strip()\n",
        "                elif isinstance(result, dict):\n",
        "                    return result.get('generated_text', '').strip()\n",
        "            else:\n",
        "                return self._simple_answer_extraction(prompt)\n",
        "        except Exception as e:\n",
        "            print(f\"API Error: {e}\")\n",
        "            return self._simple_answer_extraction(prompt)\n",
        "\n",
        "    def _simple_answer_extraction(self, prompt: str) -> str:\n",
        "        \"\"\"\n",
        "        Simple fallback method to extract answers from context\n",
        "        \"\"\"\n",
        "        if \"Question:\" in prompt and \"Context:\" in prompt:\n",
        "            context_start = prompt.find(\"Context:\") + 8\n",
        "            question_start = prompt.find(\"Question:\") + 9\n",
        "            context = prompt[context_start:prompt.find(\"Question:\")].strip()\n",
        "            question = prompt[question_start:].strip()\n",
        "\n",
        "            question_lower = question.lower()\n",
        "            context_lines = context.split('\\n')\n",
        "\n",
        "            for line in context_lines:\n",
        "                if any(word in line for word in question.split() if len(word) > 2):\n",
        "                    words = line.split()\n",
        "                    if len(words) > 0:\n",
        "                        return line.strip()[:100]\n",
        "\n",
        "        return \"à¦¤à¦¥à§à¦¯ à¦ªà¦¾à¦“à¦¯à¦¼à¦¾ à¦¯à¦¾à¦¯à¦¼à¦¨à¦¿\"\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"huggingface\""
      ],
      "metadata": {
        "id": "agSimBoXXAxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BilingualRAGPipeline:\n",
        "    def __init__(self, file_path: str):\n",
        "        \"\"\"\n",
        "        Initialize the bilingual RAG pipeline\n",
        "\n",
        "        Args:\n",
        "            file_path (str): Path to the text file containing chunked data\n",
        "        \"\"\"\n",
        "        self.file_path = file_path\n",
        "        self.vectorstore = None\n",
        "        self.retriever = None\n",
        "        self.qa_chain = None\n",
        "\n",
        "        print(\"Initializing multilingual embeddings...\")\n",
        "        self.embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
        "            model_kwargs={'device': 'cpu'}\n",
        "        )\n",
        "\n",
        "        print(\"Initializing language model...\")\n",
        "        self.llm = HuggingFaceLLM()\n",
        "\n",
        "    def load_and_prepare_documents(self) -> List[Document]:\n",
        "        \"\"\"\n",
        "        Load the text file and convert chunks to LangChain Document format\n",
        "\n",
        "        Returns:\n",
        "            List[Document]: List of Document objects\n",
        "        \"\"\"\n",
        "        print(f\"Loading documents from: {self.file_path}\")\n",
        "\n",
        "        documents = []\n",
        "\n",
        "        try:\n",
        "            with open(self.file_path, 'r', encoding='utf-8') as file:\n",
        "                content = file.read()\n",
        "\n",
        "            #spliting the chunks\n",
        "            if '\\n\\n' in content:\n",
        "                chunks = content.split('\\n\\n')\n",
        "            else:\n",
        "                chunks = content.split('\\n')\n",
        "\n",
        "            # Removing empty chunks\n",
        "            chunks = [chunk.strip() for chunk in chunks if chunk.strip()]\n",
        "\n",
        "            for idx, chunk in enumerate(chunks):\n",
        "                if len(chunk) > 10:\n",
        "                    documents.append(Document(\n",
        "                        page_content=chunk,\n",
        "                        metadata={\n",
        "                            'chunk_id': idx,\n",
        "                            'source': f\"chunk_{idx}\",\n",
        "                            'length': len(chunk)\n",
        "                        }\n",
        "                    ))\n",
        "\n",
        "            print(f\"Loaded {len(documents)} document chunks\")\n",
        "            return documents\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"File not found: {self.file_path}\")\n",
        "            return []\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading file: {e}\")\n",
        "            return []\n",
        "\n",
        "    def create_vectorstore(self, documents: List[Document]):\n",
        "        \"\"\"\n",
        "        Create Chroma vectorstore from documents\n",
        "\n",
        "        Args:\n",
        "            documents (List[Document]): List of documents to vectorize\n",
        "        \"\"\"\n",
        "        print(\"Creating vector store...\")\n",
        "\n",
        "        if not documents:\n",
        "            print(\"No documents to process!\")\n",
        "            return\n",
        "\n",
        "        # Creating Chroma vectorstore\n",
        "        self.vectorstore = Chroma.from_documents(\n",
        "            documents=documents,\n",
        "            embedding=self.embeddings,\n",
        "            persist_directory=\"/content/chroma_db\"\n",
        "        )\n",
        "\n",
        "        self.retriever = self.vectorstore.as_retriever(\n",
        "            search_type=\"similarity\",\n",
        "            search_kwargs={\"k\": 3}\n",
        "        )\n",
        "\n",
        "        print(\"Vector store created successfully!\")\n",
        "\n",
        "    def setup_qa_chain(self):\n",
        "        \"\"\"\n",
        "        Set up the question-answering chain with custom prompt template\n",
        "        \"\"\"\n",
        "        print(\"Setting up QA chain...\")\n",
        "\n",
        "        prompt_template = \"\"\"Based on the following context, answer the question concisely.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Provide a direct, short answer. If the question is in Bengali, answer in Bengali. If in English, answer in English.\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "        PROMPT = PromptTemplate(\n",
        "            template=prompt_template,\n",
        "            input_variables=[\"context\", \"question\"]\n",
        "        )\n",
        "\n",
        "        self.qa_chain = RetrievalQA.from_chain_type(\n",
        "            llm=self.llm,\n",
        "            chain_type=\"stuff\",\n",
        "            retriever=self.retriever,\n",
        "            chain_type_kwargs={\"prompt\": PROMPT},\n",
        "            return_source_documents=True\n",
        "        )\n",
        "\n",
        "        print(\"QA chain setup complete!\")\n",
        "\n",
        "    def query(self, question: str) -> dict:\n",
        "        \"\"\"\n",
        "        Query the RAG pipeline with enhanced answer extraction\n",
        "\n",
        "        Args:\n",
        "            question (str): Question to ask\n",
        "\n",
        "        Returns:\n",
        "            dict: Answer and source documents\n",
        "        \"\"\"\n",
        "        if not self.qa_chain:\n",
        "            raise ValueError(\"QA chain not initialized. Run setup() first.\")\n",
        "\n",
        "        print(f\"Processing query: {question}\")\n",
        "\n",
        "        try:\n",
        "            relevant_docs = self.retriever.get_relevant_documents(question)\n",
        "\n",
        "            answer = self._extract_answer_from_context(question, relevant_docs)\n",
        "\n",
        "            return {\n",
        "                \"question\": question,\n",
        "                \"answer\": answer,\n",
        "                \"source_documents\": relevant_docs\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing query: {e}\")\n",
        "            return {\n",
        "                \"question\": question,\n",
        "                \"answer\": \"à¦‰à¦¤à§à¦¤à¦° à¦–à§à¦à¦œà§‡ à¦ªà¦¾à¦“à¦¯à¦¼à¦¾ à¦¯à¦¾à¦¯à¦¼à¦¨à¦¿\",\n",
        "                \"source_documents\": []\n",
        "            }\n",
        "\n",
        "    def _extract_answer_from_context(self, question: str, docs: List[Document]) -> str:\n",
        "        \"\"\"\n",
        "        Enhanced answer extraction using pattern matching\n",
        "        \"\"\"\n",
        "        context = \" \".join([doc.page_content for doc in docs])\n",
        "\n",
        "        if \"à¦•à¦¾à¦°\" in question or \"à¦•à§‹à¦¨\" in question or \"à¦•à¦¿\" in question or \"à¦•à¦¤\" in question:\n",
        "            lines = context.split('à¥¤')\n",
        "\n",
        "            for line in lines:\n",
        "                if \"à¦¬à¦¯à¦¼à¦¸\" in question and \"à§§à§«\" in line:\n",
        "                    if \"à¦¬à¦›à¦°\" in line:\n",
        "                        return \"à§§à§« à¦¬à¦›à¦°\"\n",
        "\n",
        "                if \"à¦¸à¦ªà§à¦°à§à¦·\" in question or \"à¦¸à§à¦ªà§à¦°à§à¦·\" in question:\n",
        "                    words = line.split()\n",
        "                    for i, word in enumerate(words):\n",
        "                        if \"à¦¶à§à¦®à§à¦­à¦¨à¦¾à¦¥\" in word:\n",
        "                            return \"à¦¶à§à¦®à§à¦­à¦¨à¦¾à¦¥\"\n",
        "\n",
        "                if \"à¦­à¦¾à¦—à§à¦¯ à¦¦à§‡à¦¬à¦¤à¦¾\" in question or \"à¦®à¦¾à¦®à§‹\" in question:\n",
        "                    if \"à¦®à¦¾à¦®à§‹\" in line:\n",
        "                        return \"à¦®à¦¾à¦®à§‹\"\n",
        "\n",
        "        sentences = context.split('à¥¤')\n",
        "        for sentence in sentences[:3]:\n",
        "            if len(sentence.strip()) > 5:\n",
        "                return sentence.strip()[:50]\n",
        "\n",
        "        return \"à¦¤à¦¥à§à¦¯ à¦ªà¦¾à¦“à¦¯à¦¼à¦¾ à¦¯à¦¾à¦¯à¦¼à¦¨à¦¿\"\n",
        "\n",
        "    def setup(self):\n",
        "        \"\"\"\n",
        "        Complete setup of the RAG pipeline\n",
        "        \"\"\"\n",
        "        print(\"Setting up Bilingual RAG Pipeline...\")\n",
        "\n",
        "        documents = self.load_and_prepare_documents()\n",
        "\n",
        "        if not documents:\n",
        "            print(\"No documents loaded. Please check the file path.\")\n",
        "            return False\n",
        "\n",
        "        self.create_vectorstore(documents)\n",
        "\n",
        "        self.setup_qa_chain()\n",
        "\n",
        "        print(\"RAG Pipeline setup complete!\")\n",
        "        return True\n",
        "\n"
      ],
      "metadata": {
        "id": "0AfCBS1wXAoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    file_path = \"/content/drive/MyDrive/dataset/HSC26_chunks.txt\"\n",
        "\n",
        "    print(\"ğŸš€ Starting Bilingual RAG Pipeline Setup...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    rag_pipeline = BilingualRAGPipeline(file_path)\n",
        "\n",
        "    success = rag_pipeline.setup()\n",
        "\n",
        "    if not success:\n",
        "        print(\"Failed to setup pipeline. Please check your file path.\")\n",
        "        return\n",
        "\n",
        "    test_questions = [\n",
        "        \"à¦…à¦¨à¦ªà§‡à¦®à¦° à¦­à¦¾à¦·à¦¾à¦¯à¦¼ à¦¸à¦ªà§à¦°à§à¦· à¦•à¦¾à§‡à¦• à¦¬à¦²à¦¾ à¦¹à§‡à¦¯à¦¼à§‡à¦›?\",\n",
        "        \"à¦•à¦¾à§‡à¦• à¦…à¦¨à¦ªà§‡à¦®à¦° à¦­à¦¾à¦—à§à¦¯ à¦¦à¦¬à¦¤à¦¾ à¦¬à§‡à¦² à¦‰à§‡ à¦– à¦•à¦°à¦¾ à¦¹à§‡à¦¯à¦¼à§‡à¦›?\",\n",
        "        \"à¦¬à¦¿à¦¯à¦¼à§‡à¦° à¦¸à¦®à¦¯à¦¼ à¦•à¦²à§à¦¯à¦¾à¦£à§€à¦° à¦ªà§à¦°à¦•à¦¤ à¦¬à¦¯à¦¼à¦¸ à¦•à¦¤ à¦›à¦¿à¦²?\"\n",
        "    ]\n",
        "\n",
        "    expected_answers = [\n",
        "        \"à¦¶à§à¦®à§à¦­à¦¨à¦¾à¦¥\",\n",
        "        \"à¦®à¦¾à¦®à§‹\",\n",
        "        \"à§§à§« à¦¬à¦›à¦°\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"ğŸ§ª TESTING THE RAG PIPELINE\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for i, question in enumerate(test_questions):\n",
        "        print(f\"\\nğŸ“ Test Case {i+1}:\")\n",
        "        print(f\"Question: {question}\")\n",
        "        print(f\"Expected: {expected_answers[i]}\")\n",
        "\n",
        "        try:\n",
        "            result = rag_pipeline.query(question)\n",
        "            print(f\"Got Answer: {result['answer']}\")\n",
        "\n",
        "            if expected_answers[i].lower() in result['answer'].lower():\n",
        "                print(\"âœ… MATCH!\")\n",
        "            else:\n",
        "                print(\"âŒ Different answer\")\n",
        "\n",
        "            if result['source_documents']:\n",
        "                print(f\"ğŸ“„ Source Context (first 100 chars):\")\n",
        "                print(f\"   {result['source_documents'][0].page_content[:100]}...\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error: {str(e)}\")\n",
        "\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    print(\"\\nğŸ‰ Testing Complete!\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"ğŸ’¬ INTERACTIVE TESTING\")\n",
        "    print(\"Type your questions (Bengali or English), or 'quit' to exit\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            user_question = input(\"\\nğŸ¤” Your Question: \").strip()\n",
        "\n",
        "            if user_question.lower() in ['quit', 'exit', 'à¦¬à¦¨à§à¦§']:\n",
        "                print(\"ğŸ‘‹ Goodbye!\")\n",
        "                break\n",
        "\n",
        "            if user_question:\n",
        "                result = rag_pipeline.query(user_question)\n",
        "                print(f\"ğŸ¤– Answer: {result['answer']}\")\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\nğŸ‘‹ Goodbye!\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "WVS2vBCpXAfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_file_content(file_path: str, lines: int = 5):\n",
        "    \"\"\"\n",
        "    Check the first few lines of the file to understand its structure\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            content = file.read()\n",
        "            print(f\"ğŸ“ File size: {len(content)} characters\")\n",
        "            print(f\"ğŸ“„ First {lines} lines:\")\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "            lines_content = content.split('\\n')[:lines]\n",
        "            for i, line in enumerate(lines_content, 1):\n",
        "                print(f\"{i}: {line[:100]}...\")\n",
        "\n",
        "            print(\"-\" * 40)\n",
        "            return True\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error reading file: {e}\")\n",
        "        return False\n",
        "\n",
        "print(\"ğŸ” Checking your file content...\")\n",
        "file_path = \"/content/drive/MyDrive/dataset/HSC26_chunks.txt\"\n",
        "if check_file_content(file_path):\n",
        "    print(\"âœ… File found and readable!\")\n",
        "    print(\"\\nğŸš€ Starting main pipeline...\")\n",
        "    main()\n",
        "else:\n",
        "    print(\"âŒ Please check your file path and ensure the file exists.\")\n",
        "\n",
        "def quick_debug_test():\n",
        "    \"\"\"\n",
        "    Quick test with minimal setup for debugging\n",
        "    \"\"\"\n",
        "    file_path = \"/content/drive/MyDrive/dataset/HSC26_chunks.txt\"\n",
        "\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            content = file.read()[:1000]\n",
        "            print(\"Sample content:\")\n",
        "            print(content)\n",
        "\n",
        "        rag = BilingualRAGPipeline(file_path)\n",
        "        documents = rag.load_and_prepare_documents()\n",
        "        print(f\"Loaded {len(documents)} documents\")\n",
        "\n",
        "        if documents:\n",
        "            print(\"First document sample:\")\n",
        "            print(documents[0].page_content[:200])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Debug error: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACmczxytXW2e",
        "outputId": "08b2c9d2-fed8-4b83-9ad4-faa75f648f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” Checking your file content...\n",
            "ğŸ“ File size: 82863 characters\n",
            "ğŸ“„ First 5 lines:\n",
            "----------------------------------------\n",
            "1: ğŸ¯ à¦¶à¦¿à¦•à§à¦·à¦¾à¦«à¦² âœ” à¦¨à¦¿à¦°à§à¦¯à¦¾à¦¤à¦¿à¦¤ à¦¬à§à¦¯à¦•à§à¦¤à¦¿à¦° à¦¬à¦¾à¦‡à¦°à§‡ à¦¬à¦¿à¦¤à§à¦¤à¦¶à¦¾à¦²à§€ à¦¹à¦¯à¦¼à§‡ à¦“à¦ à¦¾à¦° à¦«à¦²à§‡ à¦¸à¦®à¦¾à¦œà§‡ à¦ªà¦°à¦¿à¦šà¦¯à¦¼ à¦¸à¦‚à¦•à¦Ÿ à¦¸à¦®à§à¦ªà¦°à§à¦•à§‡ à¦§à¦¾à¦°à¦£à¦¾ à¦²à¦¾à¦­ à¦•...\n",
            "2: ---...\n",
            "3: à¦¾ à¦ªà§à¦°à¦¤à¦¿à¦¸à§à¦¥à¦¾à¦ªà¦¿à¦¤ à¦à¦‡ à¦¸à¦¤à§à¦¯ à¦…à¦¨à§à¦§à¦¾à¦¬à¦¨ à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à¦¬à§‡à¥¤ âœ” à¦®à¦¾à¦¨à§à¦· à¦†à¦¶à¦¾ à¦¨à¦¿à¦¯à¦¼à§‡ à¦¬à§‡à¦à¦šà§‡ à¦¥à¦¾à¦•à§‡ \\- à¦…à¦¨à§à¦ªà§à¦°à§‡à¦°à¦£à¦¾à¦° à¦¦à§ƒà¦·à§à¦Ÿà¦¿à¦¤à§‡ à¦®à¦¾à¦¨à¦¬...\n",
            "4: ---...\n",
            "5: ï¿½ à¦ªà¦¿à¦à¦ªà¦¡à¦¼à¦¿à¦° à¦¦à§€à¦ªà§ à¦šà¦¾à¦šà¦¾ à¦›à¦¿à¦²à§‡à¦¨ à¦ªà¦¬à¦¿à¦°à§‡à¦° à¦•à¦°à§à¦¤à§à¦¤à¦¾à¥¤ à¦¦à§€à¦ªà§ à¦¶à¦¿à¦•à§à¦·à¦¿à¦¤ à¦¹à¦²à§‡à¦“ à¦¤à¦¾à¦° à¦¸à¦¿à¦¦à§à¦§à¦¾à¦¨à§à¦¤ à¦¨à§‡à¦“à¦¯à¦¼à¦¾à¦° à¦•à§à¦·à¦®à¦¤à¦¾ à¦›à¦¿à¦² à¦¨à¦¾à¥¤ à¦šà¦¾...\n",
            "----------------------------------------\n",
            "âœ… File found and readable!\n",
            "\n",
            "ğŸš€ Starting main pipeline...\n",
            "ğŸš€ Starting Bilingual RAG Pipeline Setup...\n",
            "============================================================\n",
            "Initializing multilingual embeddings...\n",
            "Initializing language model...\n",
            "Setting up Bilingual RAG Pipeline...\n",
            "Loading documents from: /content/drive/MyDrive/dataset/HSC26_chunks.txt\n",
            "Loaded 133 document chunks\n",
            "Creating vector store...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-12-1618746824.py:150: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  relevant_docs = self.retriever.get_relevant_documents(question)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector store created successfully!\n",
            "Setting up QA chain...\n",
            "QA chain setup complete!\n",
            "RAG Pipeline setup complete!\n",
            "\n",
            "============================================================\n",
            "ğŸ§ª TESTING THE RAG PIPELINE\n",
            "============================================================\n",
            "\n",
            "ğŸ“ Test Case 1:\n",
            "Question: à¦…à¦¨à¦ªà§‡à¦®à¦° à¦­à¦¾à¦·à¦¾à¦¯à¦¼ à¦¸à¦ªà§à¦°à§à¦· à¦•à¦¾à§‡à¦• à¦¬à¦²à¦¾ à¦¹à§‡à¦¯à¦¼à§‡à¦›?\n",
            "Expected: à¦¶à§à¦®à§à¦­à¦¨à¦¾à¦¥\n",
            "Processing query: à¦…à¦¨à¦ªà§‡à¦®à¦° à¦­à¦¾à¦·à¦¾à¦¯à¦¼ à¦¸à¦ªà§à¦°à§à¦· à¦•à¦¾à§‡à¦• à¦¬à¦²à¦¾ à¦¹à§‡à¦¯à¦¼à§‡à¦›?\n",
            "Got Answer: ï¿½à¦Ÿà¦¾ à¦¨à¦¿à¦¤à¦¾à¦¨à§à¦¤ à¦¨à¦¿à¦°à§à¦œà§€à¦¬, à¦à¦•à¦¬à¦¾à¦°à§‡ à¦•à§‹à¦¨à§‹ à¦¤à§‡à¦œ à¦¨à¦¾à¦‡\n",
            "âŒ Different answer\n",
            "ğŸ“„ Source Context (first 100 chars):\n",
            "   ï¿½à¦Ÿà¦¾ à¦¨à¦¿à¦¤à¦¾à¦¨à§à¦¤ à¦¨à¦¿à¦°à§à¦œà§€à¦¬, à¦à¦•à¦¬à¦¾à¦°à§‡ à¦•à§‹à¦¨à§‹ à¦¤à§‡à¦œ à¦¨à¦¾à¦‡à¥¤ à¦¬à§‡à¦¹à¦¾à¦‡-à¦¸à¦®à§à¦ªà¦¦à¦¾à¦¨à§‡à¦° à¦†à¦° à¦¯à¦¾à¦‡ à¦¥à¦¾à¦•, à¦¤à§‡à¦œ à¦¥à¦¾à¦•à¦Ÿà¦¾ à¦¦à§‹à¦·à§‡à¦°, à¦…à¦¤à¦à¦¬ à¦®à¦¾à¦®à¦¾ à¦®à¦¨à§‡...\n",
            "--------------------------------------------------\n",
            "\n",
            "ğŸ“ Test Case 2:\n",
            "Question: à¦•à¦¾à§‡à¦• à¦…à¦¨à¦ªà§‡à¦®à¦° à¦­à¦¾à¦—à§à¦¯ à¦¦à¦¬à¦¤à¦¾ à¦¬à§‡à¦² à¦‰à§‡ à¦– à¦•à¦°à¦¾ à¦¹à§‡à¦¯à¦¼à§‡à¦›?\n",
            "Expected: à¦®à¦¾à¦®à§‹\n",
            "Processing query: à¦•à¦¾à§‡à¦• à¦…à¦¨à¦ªà§‡à¦®à¦° à¦­à¦¾à¦—à§à¦¯ à¦¦à¦¬à¦¤à¦¾ à¦¬à§‡à¦² à¦‰à§‡ à¦– à¦•à¦°à¦¾ à¦¹à§‡à¦¯à¦¼à§‡à¦›?\n",
            "Got Answer: à¦¿à¦°à¦ªà¦°à¦¿à¦šà¦¯à¦¼à§‡à¦° à¦†à¦¸à¦¨à¦Ÿà¦¿à¦° à¦‰à¦ªà¦°à§‡ à¦†à¦¸à¦¿à¦¯à¦¼à¦¾ à¦¬à¦¸à¦¿à¦¯à¦¼à¦¾à¦›\n",
            "âŒ Different answer\n",
            "ğŸ“„ Source Context (first 100 chars):\n",
            "   à¦¿à¦°à¦ªà¦°à¦¿à¦šà¦¯à¦¼à§‡à¦° à¦†à¦¸à¦¨à¦Ÿà¦¿à¦° à¦‰à¦ªà¦°à§‡ à¦†à¦¸à¦¿à¦¯à¦¼à¦¾ à¦¬à¦¸à¦¿à¦¯à¦¼à¦¾à¦›à¥¤ à¦•à§€ à¦†à¦¶à§à¦šà¦°à§à¦¯ à¦ªà¦°à¦¿à¦ªà§‚à¦°à§à¦£ à¦¤à§à¦®à¦¿ \\- à¦šà¦à§à¦šà¦² à¦•à¦¾à¦²à§‡à¦° à¦•à§à¦·à§à¦¦à§à¦§ à¦¹à§ƒà¦¦à¦¯à¦¼à§‡à¦° à¦‰à¦ªà¦°à§‡ ...\n",
            "--------------------------------------------------\n",
            "\n",
            "ğŸ“ Test Case 3:\n",
            "Question: à¦¬à¦¿à¦¯à¦¼à§‡à¦° à¦¸à¦®à¦¯à¦¼ à¦•à¦²à§à¦¯à¦¾à¦£à§€à¦° à¦ªà§à¦°à¦•à¦¤ à¦¬à¦¯à¦¼à¦¸ à¦•à¦¤ à¦›à¦¿à¦²?\n",
            "Expected: à§§à§« à¦¬à¦›à¦°\n",
            "Processing query: à¦¬à¦¿à¦¯à¦¼à§‡à¦° à¦¸à¦®à¦¯à¦¼ à¦•à¦²à§à¦¯à¦¾à¦£à§€à¦° à¦ªà§à¦°à¦•à¦¤ à¦¬à¦¯à¦¼à¦¸ à¦•à¦¤ à¦›à¦¿à¦²?\n",
            "Got Answer: ï¿½à¦¾à¦¡à¦¼à¦¿ à¦šà¦²à¦¿à¦²; à¦†à¦®à¦¿ à¦œà¦¾à¦¨à¦²à¦¾à¦° à¦•à¦¾à¦›à§‡ à¦¬à¦¸à¦¿à¦¯à¦¼à¦¾ à¦°à¦¹à¦¿à¦²à¦¾à¦®\n",
            "âŒ Different answer\n",
            "ğŸ“„ Source Context (first 100 chars):\n",
            "   ï¿½à¦¾à¦¡à¦¼à¦¿ à¦šà¦²à¦¿à¦²; à¦†à¦®à¦¿ à¦œà¦¾à¦¨à¦²à¦¾à¦° à¦•à¦¾à¦›à§‡ à¦¬à¦¸à¦¿à¦¯à¦¼à¦¾ à¦°à¦¹à¦¿à¦²à¦¾à¦®à¥¤ à¦†à¦®à¦¾à¦° à¦šà§‹à¦–à§‡à¦° à¦¸à¦¾à¦®à¦¨à§‡ à¦•à§‹à¦¨à§‹ à¦®à§‚à¦°à§à¦¤à¦¿ à¦›à¦¿à¦² à¦¨à¦¾, à¦•à¦¿à¦¨à§à¦¤à§ à¦¹à§ƒà¦¦à¦¯à¦¼à§‡à¦° à¦®à¦§à§à¦¯à§‡...\n",
            "--------------------------------------------------\n",
            "\n",
            "ğŸ‰ Testing Complete!\n",
            "\n",
            "============================================================\n",
            "ğŸ’¬ INTERACTIVE TESTING\n",
            "Type your questions (Bengali or English), or 'quit' to exit\n",
            "============================================================\n",
            "\n",
            "ğŸ¤” Your Question: à¦•à¦²à§à¦¯à¦¾à¦£à§€ à¦•à§‡?\n",
            "Processing query: à¦•à¦²à§à¦¯à¦¾à¦£à§€ à¦•à§‡?\n",
            "ğŸ¤– Answer: à¦¯à¦¾à¦°à¦¾ à¦®à¦¨à§‡ à¦•à¦°à§‡ à¦¤à¦¾à¦¦à§‡à¦° à¦¹à¦¾à¦¤à§‡ à¦†à¦®à¦¿ à¦•à¦¨à§à¦¯à¦¾ à¦¦à¦¿à¦¤à§‡ à¦ªà¦¾à¦°à¦¿ à¦¨à¦¾\n",
            "\n",
            "ğŸ¤” Your Question: who is Anupam?\n",
            "Processing query: who is Anupam?\n",
            "ğŸ¤– Answer: with sorrow; it is through Anupam's sincere narrat\n",
            "\n",
            "ğŸ¤” Your Question: à¦°à¦¬à§€à¦¨à§à¦¦à§à¦°à¦¨à¦¾à¦¥ à¦•à¦¤ à¦¸à¦¾à¦²à§‡ à¦œà¦¨à§à¦® à¦¨à§‡à§Ÿ?\n",
            "Processing query: à¦°à¦¬à§€à¦¨à§à¦¦à§à¦°à¦¨à¦¾à¦¥ à¦•à¦¤ à¦¸à¦¾à¦²à§‡ à¦œà¦¨à§à¦® à¦¨à§‡à§Ÿ?\n",
            "ğŸ¤– Answer: à¦¹à¦¿à¦¸à¦¾à¦¬à§‡\n",
            "\n",
            "ğŸ¤” Your Question: quit\n",
            "ğŸ‘‹ Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x_z5Qp7uXWw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b2WpTMBnXWrY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}